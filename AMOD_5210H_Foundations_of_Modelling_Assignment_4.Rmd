---
title: "**AMOD-5210H: Foundations of Modelling**"
author: "Jasmeet Singh Saini - 0758054"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
library(rstatix)
library(effectsize)
library(chisq.posthoc.test)
library(psych)
library(rstatix)
library(ggplot2)
library(caret)
library(ez)
```

# PART 1: EFFECT SIZES

The following questions requires the use of **"healthdata.xlsx"**. 

Firstly, loading the required packages and then reading the excel file.

```{r}
health_dataset <- read_excel("health-data.xlsx")
```

Now, let's performing data extraction.


```{r}
set.seed(0758054)
index <- sample(1:nrow(health_dataset),200)
AMOD5210_Part1 <- health_dataset[index, ]
```

## Part 1: Question 1

### Using an appropriate inferential statistic and effect size, determine whether there is a significant difference between students and non-students on "Health" and "Depress".

**For the variable "Health":**

### Step 1 : Hypothesis & Assumptions

The $H_{0}$ is Null hypothesis and $H_{A}$ is Alternative hypothesis.

$$
\begin{aligned}
H_{0}:\ &\text{There is no difference in "health" variable for students and non-students.} \\
&\qquad \qquad \qquad \qquad \qquad \qquad \text{vs.} \\
H_{A}:\ &\text{There is a difference in "health" variable for students and non-students.}
\end{aligned}
$$

Let's check the head of Health dataset
```{r}
head(AMOD5210_Part1, 3)
```

Now, let's grouping with students and checking the summary.

```{r}
grouping_student <- group_by(AMOD5210_Part1, Student)
get_summary_stats(grouping_student, Health, type="mean_sd")
```

Now, we need to test some **assumptions** about our data.

```{r}
identify_outliers(grouping_student, Health)
```

Here, We get no outliers. We will now test for **normality** from the health-data. For that, we will use the **Shapiro-Wilks Test**. If $p > 0.05$, the data is normal.

```{r}
shapiro_test(grouping_student, Health)
```

Now, we need to test for **homogeneity of variance**. We can use the **Levene's Test** for this. If $p > 0.05$, variances are homogeneous.

```{r}
levene_test(AMOD5210_Part1, Health ~ Student)
```

### Step 2 : Testing

Now, we will run **Independent t-test**. Since, the homogeneity of variance assumption was not violated, we will set var.equal to TRUE.

```{r}
t_test(AMOD5210_Part1, Health ~ Student, var.equal=TRUE)
```

Since, $p < 0.05$, the test shows a significant difference. We have enough evidence to reject the null hypothesis, $H_{O}$.

**Calculating Cohen's d**

Also, the t-Test is significant, we need to calculate **Cohen's d** for our effect size. We need to specify "paired = FALSE" to indicate the groups are independent, and specify "pooled_sd = TRUE" to indicate the variances are equal.

```{r}
cohens_d(Health ~ Student, data = AMOD5210_Part1, paired = FALSE, pooled_sd = TRUE)
```

Based on Cohen's (1988) conventions we have a small effect. 

### Step 3 : Conclusion

The current study sought to determine whether or not there is a significant difference between students and non-students on “Health”. 200 study participants were randomly sampled from the general public (39 students, 161 non-students). The sample contained no extreme outliers. A Shapiro-Wilks test demonstrated normality by group, and Levene’s test demonstrated homogeneity of variance. The mean "Health" variable of non-students in the sample was 16.112 (SD = 5.020) whereas the mean "Health" variable of the students in the sample was 18.462 (SD = 5.088). A Welch’s independent t-test showed that the mean difference in "Health" variable between student and non-students in the sample was statistically significant, $t(198) = -2.615876$, $p < 0.05$, $d = -0.47$, with students tending to be more "Healthy" than non-students. According to Cohen’s (1988) conventions, this is a small effect.

**For the variable "Depress":**

### Step 1 : Hypothesis & Assumptions

The $H_{0}$ is Null hypothesis and $H_{A}$ is Alternative hypothesis.

$$
\begin{aligned}
H_{0}:\ &\text{There is no difference in "depress" variable for students and non-students.} \\
&\qquad \qquad \qquad \qquad \qquad \qquad \text{vs.} \\
H_{A}:\ &\text{There is a difference in "depress" variable for students and non-students.}
\end{aligned}
$$

```{r}
get_summary_stats(grouping_student, Depress, type="mean_sd")
```

Now, we need to test some **assumptions** about our data.

```{r}
identify_outliers(grouping_student, Depress)
```

Here, We get no outliers. We will now test for **normality** from the health-data. For that, we will use the **Shapiro-Wilks Test**. If $p > 0.05$, the data is normal.

```{r}
shapiro_test(grouping_student, Depress)
```
It can be seen that our data is not normal. We are still going to proceed with the test.

Now, we need to test for **homogeneity of variance**. We can use the **Levene's Test** for this. If $p > 0.05$, variances are homogeneous.

```{r}
levene_test(AMOD5210_Part1, Depress ~ Student)
```

### Step 2 : Testing

Now, we will run **Independent t-test**. Since, the homogeneity of variance assumption was not violated, we will set var.equal to TRUE.

```{r}
t_test(AMOD5210_Part1, Depress ~ Student, var.equal=TRUE)
```

Since, $p < 0.05$, the test shows a significant difference. We have enough evidence to reject the null hypothesis, $H_{O}$.

**Calculating Cohen's d**

Also, the t-Test is significant, we need to calculate **Cohen's d** for our effect size. We need to specify "paired = FALSE" to indicate the groups are independent, and specify "pooled_sd = TRUE" to indicate the variances are equal.

```{r}
cohens_d(Depress ~ Student, data = AMOD5210_Part1, paired = FALSE, pooled_sd = TRUE)
```
Based on Cohen's (1988) conventions we have a small effect.

### Step 3 : Conclusion

The current study sought to determine whether or not there is a significant difference between students and non-students on variable “Depress”. 200 study participants were randomly sampled from the general public (39 students, 161 non-students). The sample contained no extreme outliers. A Shapiro-Wilks test demonstrated normality by group, and Levene’s test demonstrated homogeneity of variance. The mean "Depress" variable of non-students in the sample was 4.826 (SD = 4.445) whereas the mean "Depress" variable of the students in the sample was 6.974	(SD = 5.055). A Welch’s independent t-test showed that the mean difference in "Depress" variable between student and non-students in the sample was statistically significant, $t(198) = -2.634914$, $p < 0.05$, $d = -0.47$, with students tending to be more "Depress" than non-students. According to Cohen’s (1988) conventions, this is a small effect.

\newpage
## Part 1: Question 2 

### Using an appropriate inferential statistic and effect size, determine whether there is a significant difference in the proportion of men and women diagnosed with or without depression.

We are going to use a $\chi 2$ Test of Independence for this question.

### Step 1 : Hypothesis & Assumptions

The $H_{0}$ is Null hypothesis and $H_{A}$ is Alternative hypothesis.

$$
\begin{aligned}
H_{0}:\ &\text{There is no difference in the proportion of men and women diagnosed with or without depression.} \\
&\qquad \qquad \qquad \qquad \qquad \qquad \text{vs.} \\
H_{A}:\ &\text{There is a significant difference in the proportion of men and women diagnosed with or without depression.}
\end{aligned}
$$

Below is the frequency table based on the continuous variable Gender and Dstatus:

```{r}
frequency_table <- table(AMOD5210_Part1$Gender, AMOD5210_Part1$Dstatus)
frequency_table
```

### Step 2 : Testing

Let us now perform the test, **$\chi 2$ Test of Independence**.

```{r}
chisq.test(x = frequency_table, correct = FALSE)
chisq.posthoc.test(frequency_table)
```

Since $p > 0.05$ we fail to reject the null hypothesis, $H_{O}$.

Let's perform **Post-hoc Analysis** test:

```{r}
chisq.posthoc.test(frequency_table)
```

**Calculating Cohen's d**

Now, need to calculate the odds ratio as our **effect size**.

```{r}
oddsratio(frequency_table)
```

Based on Cohens (1988) conventions, we have less than the small category.

### Step 3 : Conclusion

The present research seeks to determine whether there is a significant difference in the proportion of men and women diagnosed with or without depression. 200 people (49 Male, 151 Female) reported if they diagnosed with (16) or without depression (184). A Chi-square Test of Independence revealed that there is no difference in the proportion of men and women diagnosed with or without depression, Chi Squared(1, N = 200) = 1.3539, $p > 0.001$, OR = 0.42. According to Cohen’s (1988) conventions, this effect was small.

\newpage

## Part 1: Question 3

**Researchers are interested to determine whether character strengths are significant predictors of depression symptoms.**

### a) Using the Pearson’s r correlation and $r^2$, determine whether there are significant correlations between depression symptoms and the four character strengths variables ("Honesty", "Leader", "Persevere", "Regulation"). Report the r and p-values for each correlation. Also, report $r^2$ for each correlation.

Fristly, let's see the summary statistics:

```{r}
describe(AMOD5210_Part1, fast = TRUE)
```

Now, we need to test some assumptions about our data. Let's, check weather a sample contain any extreme outliers or not?

Let's first check  the assumptions **"Honesty" variable**.

```{r}
identify_outliers(AMOD5210_Part1, Honesty)
```

Hence, there is no extreme outliers in *"Honesty" variable*.

Checking  the **"Leader" variable**.

```{r}
identify_outliers(AMOD5210_Part1, Leader)
```

Hence, there is no extreme outliers in *"Leader" variable*.

Checking  the **"Persevere" variable**.

```{r}
identify_outliers(AMOD5210_Part1, Persevere)
```
Hence, there is no extreme outliers in *"Persevere" variable*.

Checking  the **"Regulation" variable**.

```{r}
identify_outliers(AMOD5210_Part1, Regulation)
```

Hence, there is no extreme outliers in *"Regulation" variable*.

Now, we will check if the data is **normaly distributed** or not. For that, we will use the *Shapiro-Wilks Test* for this. If $p > 0.05$, the data is normal.

```{r}
shapiro_test(AMOD5210_Part1, vars = c("Honesty", "Leader", "Persevere", "Regulation"))
```

Here, we can see that the $p < 0.05$ for all the four variables, that is, "Honesty", "Leader", "Persevere", "Regulation". And we can say that, the data is not Normal Distribution.


Finally, we need to check the *Linearity* for all the four variables, that is, "Honesty", "Leader", "Persevere", "Regulation".

```{r}
# Checking Linearity for all of the four with respect to depress variable
par(mfrow=c(1,2))
plot(AMOD5210_Part1$Depress, AMOD5210_Part1$Honesty
     , col = "green", xlab = "Depress", ylab = "Honesty"
     , main = "Depress vs Honesty")
plot(AMOD5210_Part1$Depress, AMOD5210_Part1$Leader
     , col = "blue", xlab = "Depress", ylab = "Leader"
     , main = "Depress vs Leader")

par(mfrow=c(1,2))
plot(AMOD5210_Part1$Depress, AMOD5210_Part1$Persevere
     , col = "red", xlab = "Depress", ylab = "Persevere"
       , main = "Depress vs Persevere")

plot(AMOD5210_Part1$Depress, AMOD5210_Part1$Regulation
     , col = "orange", xlab = "Depress", ylab = "Regulation"
     , main = "Depress vs Regulation")
```

None of the four variables shows the Linearity. Hence, we can say that the Linearity condition is not satisfied.  

**Pearson's r Correlation test**

Now, we will run **Pearson's r Correlation test** for all the four variables, that is, "Honesty", "Leader", "Persevere", "Regulation".

The proportion of variability in Depress variable explained by the other Honesty is given below:

```{r}
corr_honesty <- corr.test(AMOD5210_Part1$Depress, AMOD5210_Part1$Honesty, method = "pearson")
corr_honesty
```

The values are given below:

```{r}
# p-Value is
corr_honesty$p 

# R Value is
corr_honesty$r

# R Square Value, coefficient of determination is
corr_honesty$r^2
```

The *p-value* is **0.00069**.Here, $p-value < 0.05$, this Correlation for Depress vs Honesty is not significant. 

The **Pearson’s**, $r$ is **-0.23** and **coefficient of determination**, $r^2$ is **0.056**. Hence, both shows **small** effect sizes.


The proportion of variability in Depress variable explained by the other Leader is given below:

```{r}
corr_leader <- corr.test(AMOD5210_Part1$Depress, AMOD5210_Part1$Leader, method = "pearson")
corr_leader
```

The values are given below:

```{r}
# p-Value is
corr_leader$p 

# R Value is
corr_leader$r

# R Square Value, coefficient of determination is
corr_leader$r^2
```

The *p-value* is **0.027**.Here, $p-value < 0.05$, this Correlation for Depress vs Honesty is not significant. 

The **Pearson’s**, $r$ is **-0.15** and **coefficient of determination**, $r^2$ is **0.024**. Hence, both shows **small** effect sizes.

The proportion of variability in Depress variable explained by the other Persevere is given below:

```{r}
corr_persevere <- corr.test(AMOD5210_Part1$Depress, AMOD5210_Part1$Persevere, method = "pearson")
corr_persevere
```

The values are given below:

```{r}
# p-Value is
corr_persevere$p

# R Value is
corr_persevere$r

# R Square Value, coefficient of determination is
corr_persevere$r^2
```

The *p-value* is **5.462712e-08**.Here, $p-value < 0.05$, this Correlation for Depress vs Honesty is not significant. 

The **Pearson’s**, $r$ is **-0.37** and **coefficient of determination**, $r^2$ is **0.14**. Hence, both shows **moderate** effect sizes.

The proportion of variability in Depress variable explained by the other Regulation is given below:

```{r}
corr_regulation <- corr.test(AMOD5210_Part1$Depress, AMOD5210_Part1$Regulation, method = "pearson")
corr_regulation
```

The values are given below:

```{r}
# p-Value is
corr_regulation$p

# R Value is
corr_regulation$r

# R Square Value, coefficient of determination is
corr_regulation$r^2
```

The *p-value* is **1.544422e-05**.Here, $p-value < 0.05$, this Correlation for Depress vs Honesty is not significant. 

The **Pearson’s**, $r$ is **--0.3004** and **coefficient of determination**, $r^2$ is **0.0902**. Hence, both shows **moderate** effect sizes.


### b) Using multiple linear regression, determine whether the four character strengths variables are significant predictors of depression symptoms. Report the slopes and p-values for each character strength and identify which character strengths were significant predictors. Also report and interpret the multiple $R^2$ for the overall model.



We can create our model using the lm() function and store the model as an object, to test **multiple regression test**. Then, we will check the summary.

```{r}
regress.model <- lm(Depress ~ Honesty + Leader + Persevere + Regulation 
         , data = AMOD5210_Part1)
summary(regress.model)
```

The slopes and $p-value$ for each charter strength variables are as followers:

1. Slopes are:

      Honesty is -0.099070,      
      Leader is -0.005705,    
      Persevere is -0.377685, and 
      Regulation is -0.226089  

2. $p-value$ are:

      Honesty is 0.477496,    
      Leader is 0.956038,    
      Persevere is 0.000722, and
      Regulation is 0.014862 

We can observed from the values above that "Honesty" and "Leader" have $p-value$ greater than 0.05 making them a significant predictor.

The values of Multiple $r^2$ is **0.1695**.

According to Cohen’s d (Cohen, 1988) conventions, the overall model explained a **moderate** proportion of variability in "Depress" variable.


## Part 1: Question 4

### Using an appropriate inferential statistic and effect size(s), determine whether participants had significantly different scores across the four character strengths ("honesty", "Leader", "Persevere", "Regulation").

We will use **One Way Repeated Measures ANOVA Test** Inferential Statistic, to check whether participants had significantly different scores across the four character strengths ("honesty", "Leader", "Persevere", "Regulation"). And to measure the effect size, we will use **$\eta^2_{p}$, partial eta squared**.

### Step 1 : Hypothesis & Assumptions

The $H_{0}$ is Null hypothesis and $H_{A}$ is Alternative hypothesis.

$$
\begin{aligned}
H_{0}:\ &\text{The participants does not had significantly different scores across the four character strengths} \\
&\qquad \qquad \qquad \qquad \qquad \qquad \text{vs.} \\
H_{A}:\ &\text{The participants had significantly different scores across the four character strengths}
\end{aligned}
$$


```{r}
library(ez)
# Gathering data of different character strengths into one column
strength <- gather(data = AMOD5210_Part1
                    , key = "Character_Strength"
                    , value = "Score", Honesty, Leader, Persevere, Regulation)

# Storing the required data in a new dataframe
data_frame <- strength[ ,c("ID","Character_Strength","Score")]
tail(data_frame,5)
```

Now let's group the data and print the descriptive statistics:

```{r}
char_group <- group_by(data_frame, Character_Strength)
get_summary_stats(char_group, Score, type = "mean_sd")
```

Now, we need to test some **assumptions** about our data.

```{r}
identify_outliers(char_group, Score)
```

Here, We get no outliers. We will now test for **normality** from the Score-data. For that, we will use the **Shapiro-Wilks Test**. If $p > 0.05$, the data is normal.

```{r}
shapiro_test(char_group, Score)
```

Here, $p-value < 0.05$ and it can be seen that our data is not normally distributed for all groups. We are still going to proceed with the test.

### Step 2 : Testing
 
Now we will performing **One Way Repeated Measures ANOVA Test**.

```{r}
rep_ANOVA <- ezANOVA(data_frame, dv = Score, wid = ID
                      , within = Character_Strength, type=3
                      , return_aov = TRUE)
# Printing rep_ANOVA
rep_ANOVA
```

In the ANOVA section, since p-value is less than 0.05, we will **reject** the null hypothesis, $H_{O}$. Thus, we can conclude that participants had significantly different scores across the four character strengths. 

Calculating **Partial Eta Squared Effect Size Calculation**

Now, need to calculate the **effect size**.

```{r}
eta_squared(rep_ANOVA$aov, partial = TRUE)
```

Hence, $\eta^2_{p}$ is 0.33 and based on Cohen’s (1998) conventions, we have a Large Effect.

Now let's run our **post-hoc test**

```{r}
t_test(data_frame, Score ~ Character_Strength, paired = TRUE, p.adjust.method = "bonferroni")
```

Since adjusted $p < 0.05$ for all of the comparisons, we can say that Scores were Significantly Different
across each Character Strength.

calculating effect size for each Pairwise Comparison:

Next, we need to calculate our effect size for each pairwise comparison, cohen's d. Again, we need to use the cohens_d() function from the "rstatix" package, so we first have to detach the "effectsize" package.

```{r}
detach("package:effectsize", unload = TRUE)
```

We also need to specify “paired = TRUE” to indicate the data is paired.

```{r}
cohens_d(data_frame, Score ~ Character_Strength, paired = TRUE)
```

### Step 3 : Conclusion

The current study sought to test whether the participants had significantly different scores across the four character strengths. 200 people were randomly sampled and their scores were measured across 4 different character strengths. Shapiro-Wilks tests on the distribution of scores across each character strength
did not demonstrate normality and Mauchly’s test showed the sphericity assumption was met. The mean
score for the sample across “Honesty” was 21.055 (SD = 2.525), across “Leader” was 18.175 (SD = 3.218), across
“Persevere” was 19.055 (SD = 3.401) and across “Regulation” was 16.595 (SD = 3.605). A One-Way Repeated Measures ANOVA was performed and showed a significant change across the scores of different character
strengths,  F(3,597) = 99.29, p < 0.05, $\eta^2_{p} = 0.33$. Bonferroni-corrected pairwise comparisons revealed that the score across “Leader”  and “Regulation” were significantly higher than score across “Honesty” (d = 0.84 and d = 1.19 respectively). Both the score of "Persevere" against "Honesty" and the score of "Regulation" against "Persevere" was moderate (d = 0.637 and d = 0.635 respectively). The score across “Persevere”  and “Regulation” were significantly lower than score across “Leader” (d = 0.24 and d = 0.35 respectively). According to Cohen’s (1988) conventions, the “Leader” and “Regulation” against "Honesty" is a large effect and the “Persevere” & “Regulation” against "Leader" is a moderate effect and “Persevere” & “Regulation” against "Leader" is a small effect.

\newpage

# PART 2: DIAGNOSTIC EFFICIENCY STATISTICS


The following questions requires the use of **"diagnostic-data.xlsx"**. 

Firstly, loading the required packages and then reading the excel file.

```{r}
library(readxl)
diagnostic_dataset <- read_excel("diagnostic-data.xlsx")
```

Now, let's performing data extraction.

```{r}
set.seed(0758054)
index <- sample(1:nrow(diagnostic_dataset),200)
AMOD5210_Part2 <- diagnostic_dataset[index, ]
```

## Part 2: Question 1

### Create a 2 x 2 contingency table for the variables Diagnosis and Test. The contingency table you create should include frequencies within each cell, and each row and column of the table should be meaningfully labelled.

To create a 2 x 2 contingency table for the variables Diagnosis and Test, we will first specify our variables are factors and add some labels.

```{r}
AMOD5210_Part2$Test <- factor(AMOD5210_Part2$Test, labels = c("Yes", "No"))
AMOD5210_Part2$Diagnosis <- factor(AMOD5210_Part2$Diagnosis, labels = c("Yes", "No"))
```

Next we will now create a contingency table.

```{r}
table(AMOD5210_Part2$Test, AMOD5210_Part2$Diagnosis, dnn = c("Test", "Diagnosis"))
```

## Part 2: Question 2

### Report the following diagnostic efficiency statistics: a) sensitivity, b) specificity, c) positive prediction value, d) negative prediction value, e) overall correct classification, and f) Kappa 

Now, we will use the confusionMatrix function to calculate our the given diagnostic efficiency statistics:

```{r}
confusionMatrix(data = AMOD5210_Part2$Test
                , reference = AMOD5210_Part2$Diagnosis
                , positive = "Yes"
                , dnn = c("Test","Diagnosis"))
```

**Conclusion:**

Following are diagnostic efficiency statistics:

a) Sensitivity = 0.8095,

b) Specificity = 0.6216, 

c) Positive Prediction Value = 0.7846,

d) Negative Prediction Value = 0.6571,

e) Overall Correct Classification (Accuracy) = 0.74, 

f) Kappa = 0.436

## Part 2: Question 3

### Based on the diagnostic efficiency statistics reported in Question 2, does the new test accurately diagnose individuals with breast cancer? Explain your answer.

We can observe, through the sensitivity value, that is, **0.8095**, that the test was better at identifying the true positive cases. Also, it was worse in identifying true negative cases. The new test was not accurate in diagnosing breast cancer in individuals due to its low kappa value, that is, **0.436** (As per the conventions for interpreting Kappa).
